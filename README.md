# Don't Overfit!!
This Case Study is based on one of the Kaggle competition problems
named “Don’t Overfit!!”. It emphasizes the most necessary step in the
building of models, that is to ensure that the model does not overfit
the training data and leads to good predictions on new unseen data.
<br>
## Business Problem:
The problem is to find a model that generalizes well, seems simple but
the catch here is that we have to find it from the extremely small
training samples and should work on the unseen testing samples
without overfitting. The main objective of this problem is to use the
existing research, algorithms, techniques or strategies that can be
used to prevent the model from overfitting to the training dataset.
These techniques or strategies will be used in the area of Feature
Engineering, Feature Selection, Oversampling dataset.
The purpose of this case study is to solve the given problem by using
the leverage that the feature engineering and feature selection will
bring to the model and to show how a well-engineered feature will
allow us to use a less complex model and thereby avoid overfit.
<br>
<br>
The dataset is obtained from the link: https://www.kaggle.com/c/dont-overfit-ii/data
1. Problem type : Binary Classification
2. Performance Metric : AUCROC (Kaggle will evaluate
using AUCROC)
3. No. of Train data point : 250 Data Points
4. No. of Test data point : 19,750 Data Points
5. No. of Features : 300 Features
